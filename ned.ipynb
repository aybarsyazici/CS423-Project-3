{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Loading anchor candidate data...\n",
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Loading item_id to statement embedding data...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytorch_utils\u001b[39;00m\n\u001b[0;32m      5\u001b[0m DATA_DIR \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\pytorch_utils.py:59\u001b[0m\n\u001b[0;32m     56\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading item_id to statement embedding data...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     57\u001b[0m \u001b[38;5;66;03m# with open(DATA_DIR + 'pkl/item_id_to_description_embedding.pkl', 'rb') as handle:\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m#     item_id_to_description_embedding = pickle.load(handle)\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m statement_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./bge_statement_features.npy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;66;03m#'./data/wiki_lite/statement_features_item_id_to_index.pickle'\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/wiki_lite/statement_bge_features_item_id_to_index.pickle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\numpy\\lib\\npyio.py:432\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    429\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m.\u001b[39mopen_memmap(file, mode\u001b[38;5;241m=\u001b[39mmmap_mode,\n\u001b[0;32m    430\u001b[0m                                   max_header_size\u001b[38;5;241m=\u001b[39mmax_header_size)\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 432\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    433\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    434\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    436\u001b[0m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[0;32m    437\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\numpy\\lib\\format.py:801\u001b[0m, in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[0;32m    800\u001b[0m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[1;32m--> 801\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    802\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    803\u001b[0m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[0;32m    804\u001b[0m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    812\u001b[0m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[0;32m    813\u001b[0m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[0;32m    814\u001b[0m         array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39mndarray(count, dtype\u001b[38;5;241m=\u001b[39mdtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import pytorch_utils\n",
    "DATA_DIR = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is cuda available?\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Loading train set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aybar\\Documents\\CS423-Project-3\\pytorch_utils.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.train_data_no_doc_start['entity_loc'] = self.train_data_no_doc_start.groupby(['doc_id']).cumcount()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Now generating context embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18288/18288 [02:08<00:00, 142.03it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f00ad4ef08d4d1caf6328ba2418d381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/572 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19db7c0dc0c2473aab7c17bebc5d30e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/572 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edc5489c706b4960aa77bb8591422d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/572 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Now generating entity embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0e52392e67044aa84ed747dc8ffe71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/572 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Length: 18288\n",
      "Entity shape: torch.Size([18288, 768])\n",
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Now calculating syntactic neighbours...\n",
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Loading test set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aybar\\Documents\\CS423-Project-3\\pytorch_utils.py:106: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.train_data_no_doc_start['entity_loc'] = self.train_data_no_doc_start.groupby(['doc_id']).cumcount()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Now generating context embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9166/9166 [00:38<00:00, 238.09it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5919689e1f1f4d97b3b1addf7e6ad4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a6e957b5d9b42a091672ec643197a8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cb28074501f4c099522807c9dee2e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Now generating entity embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e71cc0c8895481dac4fbbd7f3e4b90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/287 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity Length: 9166\n",
      "Entity shape: torch.Size([9166, 768])\n",
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Now calculating syntactic neighbours...\n"
     ]
    }
   ],
   "source": [
    "dataset = pytorch_utils.EntityDataset(device='cuda')\n",
    "test_dataset = pytorch_utils.EntityDataset(train=False, device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_item_id</th>\n",
       "      <th>information</th>\n",
       "      <th>source_item_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>596464</th>\n",
       "      <td>4934728</td>\n",
       "      <td>country of citizenship United Kingdom sport As...</td>\n",
       "      <td>Bobby Ayre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596653</th>\n",
       "      <td>4935310</td>\n",
       "      <td>country of citizenship United Kingdom sport As...</td>\n",
       "      <td>Bobby Lumley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69069</th>\n",
       "      <td>171583</td>\n",
       "      <td>country of citizenship United Kingdom sport As...</td>\n",
       "      <td>Bobby Charlton</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841390</th>\n",
       "      <td>10552652</td>\n",
       "      <td>country of citizenship United Kingdom country ...</td>\n",
       "      <td>Bobby Herbert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>925819</th>\n",
       "      <td>18719433</td>\n",
       "      <td>country of citizenship United Kingdom sport As...</td>\n",
       "      <td>Bobby Goldthorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902823</th>\n",
       "      <td>16730249</td>\n",
       "      <td>sport Association football instance of Human m...</td>\n",
       "      <td>Bobby Jeffrey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596557</th>\n",
       "      <td>4934995</td>\n",
       "      <td>country of citizenship United Kingdom country ...</td>\n",
       "      <td>Bobby Finan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246384</th>\n",
       "      <td>832731</td>\n",
       "      <td>country of citizenship United Kingdom sport As...</td>\n",
       "      <td>Bobby Campbell (English footballer)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596477</th>\n",
       "      <td>4934758</td>\n",
       "      <td>country of citizenship United Kingdom country ...</td>\n",
       "      <td>Bobby Beattie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839271</th>\n",
       "      <td>10462531</td>\n",
       "      <td>country of citizenship United Kingdom sport As...</td>\n",
       "      <td>Bobby Gough</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        source_item_id                                        information  \\\n",
       "596464         4934728  country of citizenship United Kingdom sport As...   \n",
       "596653         4935310  country of citizenship United Kingdom sport As...   \n",
       "69069           171583  country of citizenship United Kingdom sport As...   \n",
       "841390        10552652  country of citizenship United Kingdom country ...   \n",
       "925819        18719433  country of citizenship United Kingdom sport As...   \n",
       "902823        16730249  sport Association football instance of Human m...   \n",
       "596557         4934995  country of citizenship United Kingdom country ...   \n",
       "246384          832731  country of citizenship United Kingdom sport As...   \n",
       "596477         4934758  country of citizenship United Kingdom country ...   \n",
       "839271        10462531  country of citizenship United Kingdom sport As...   \n",
       "\n",
       "                          source_item_title  \n",
       "596464                           Bobby Ayre  \n",
       "596653                         Bobby Lumley  \n",
       "69069                        Bobby Charlton  \n",
       "841390                        Bobby Herbert  \n",
       "925819                     Bobby Goldthorpe  \n",
       "902823                        Bobby Jeffrey  \n",
       "596557                          Bobby Finan  \n",
       "246384  Bobby Campbell (English footballer)  \n",
       "596477                        Bobby Beattie  \n",
       "839271                          Bobby Gough  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "syntax_candidates = test_dataset.syntax_candidates[-1]\n",
    "syntax_candidates = [candidate_id['corpus_id'] for candidate_id in syntax_candidates]\n",
    "pytorch_utils.wiki_items.iloc[syntax_candidates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[PyTorch-Utils]\u001b[0m: Deleting corpus embeddings...\n"
     ]
    }
   ],
   "source": [
    "pytorch_utils.delete_corpus_embeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def collate_fn_train(batch, entity_embeddings, context_embeddings, syntax_candidates_list, device='cuda'):\n",
    "    batch_context_embeddings = []\n",
    "    batch_entity_embeddings = []\n",
    "    candidate_ids_batch = []\n",
    "    candidate_description_embeddings_batch = []\n",
    "    labels_batch = []\n",
    "    for i, data in enumerate(batch):\n",
    "        index, full_mention, full_mention_longest, item_id = data\n",
    "        if full_mention in pytorch_utils.anchor_to_candidate:\n",
    "            candidate_ids = pytorch_utils.anchor_to_candidate[full_mention].copy()\n",
    "        else:\n",
    "            candidate_ids = []\n",
    "\n",
    "        if full_mention_longest in pytorch_utils.anchor_to_candidate:\n",
    "            candidate_ids += pytorch_utils.anchor_to_candidate[full_mention_longest].copy()\n",
    "\n",
    "        \n",
    "        syntax_candidates = syntax_candidates_list[index]\n",
    "\n",
    "        candidate_ids += [pytorch_utils.wiki_items.iloc[candidate_id['corpus_id']]['source_item_id'] for candidate_id in syntax_candidates]\n",
    "\n",
    "        # Remove duplicates\n",
    "        candidate_ids = list(set(candidate_ids))\n",
    "\n",
    "        # Shuffle the candidate_ids\n",
    "        np.random.shuffle(candidate_ids)\n",
    "\n",
    "        # do we have the ground truth in candidate_ids?\n",
    "        try:\n",
    "            label = candidate_ids.index(item_id)\n",
    "        except ValueError:\n",
    "            # skip this sample\n",
    "            continue\n",
    "        \n",
    "        candidate_description_embeddings = [\n",
    "            pytorch_utils.statement_embeddings[pytorch_utils.statement_item_id_to_row[candidate_id]] if candidate_id in pytorch_utils.statement_item_id_to_row\n",
    "            else pytorch_utils.description_embeddings[pytorch_utils.description_item_id_to_row[candidate_id]]\n",
    "            for candidate_id in candidate_ids\n",
    "        ]\n",
    "\n",
    "        # pad candidate_ids with 0s\n",
    "        candidate_ids += [0] * (15 - len(candidate_ids))\n",
    "        candidate_description_embeddings += torch.zeros(15 - len(candidate_description_embeddings), 384)\n",
    "\n",
    "        candidate_description_embeddings = torch.stack(candidate_description_embeddings)\n",
    "        \n",
    "        batch_context_embeddings.append(context_embeddings[index])\n",
    "        batch_entity_embeddings.append(entity_embeddings[index])\n",
    "        candidate_ids_batch.append(candidate_ids)\n",
    "        candidate_description_embeddings_batch.append(candidate_description_embeddings)\n",
    "\n",
    "        labels_batch.append(label)\n",
    "\n",
    "    # labels is a list of integers, convert it to a tensor\n",
    "    labels_batch = torch.tensor(labels_batch, dtype=torch.long, device=device)\n",
    "    # batch_context_embeddings is a list of tensors thus we have to use stack\n",
    "    batch_context_embeddings = torch.stack(batch_context_embeddings)\n",
    "    batch_entity_embeddings = torch.stack(batch_entity_embeddings)\n",
    "    # candidate_ids_batch is a list of lists, convert it to a tensor\n",
    "    candidate_ids_batch = torch.tensor(candidate_ids_batch, dtype=torch.long, device=device)\n",
    "    candidate_description_embeddings_batch = torch.stack(candidate_description_embeddings_batch)\n",
    "\n",
    "    # move everything to device\n",
    "    batch_context_embeddings = batch_context_embeddings.to(device)\n",
    "    batch_entity_embeddings = batch_entity_embeddings.to(device)\n",
    "    candidate_ids_batch = candidate_ids_batch.to(device)\n",
    "    candidate_description_embeddings_batch = candidate_description_embeddings_batch.to(device)\n",
    "    labels_batch = labels_batch.to(device)\n",
    "\n",
    "    return batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch, labels_batch\n",
    "\n",
    "def collate_fn_test(batch, entity_embeddings, context_embeddings, syntax_candidates_list, device='cuda'):\n",
    "    batch_context_embeddings = []\n",
    "    batch_entity_embeddings = []\n",
    "    candidate_ids_batch = []\n",
    "    candidate_description_embeddings_batch = []\n",
    "    for i, data in enumerate(batch):\n",
    "        index, full_mention, full_mention_longest = data\n",
    "        if full_mention in pytorch_utils.anchor_to_candidate:\n",
    "            candidate_ids = pytorch_utils.anchor_to_candidate[full_mention].copy()\n",
    "        else:\n",
    "            candidate_ids = []\n",
    "\n",
    "        if full_mention_longest in pytorch_utils.anchor_to_candidate:\n",
    "            candidate_ids += pytorch_utils.anchor_to_candidate[full_mention_longest].copy()    \n",
    "        \n",
    "        syntax_candidates = syntax_candidates_list[index]\n",
    "\n",
    "        candidate_ids += [pytorch_utils.wiki_items.iloc[candidate_id['corpus_id']]['source_item_id'] for candidate_id in syntax_candidates]\n",
    "\n",
    "        # Remove duplicates and limit to 8 candidates\n",
    "        candidate_ids = list(set(candidate_ids))\n",
    "\n",
    "        # Shuffle the candidate_ids\n",
    "        np.random.shuffle(candidate_ids)\n",
    "\n",
    "        candidate_description_embeddings = [\n",
    "            pytorch_utils.statement_embeddings[pytorch_utils.statement_item_id_to_row[candidate_id]] if candidate_id in pytorch_utils.statement_item_id_to_row\n",
    "            else pytorch_utils.description_embeddings[pytorch_utils.description_item_id_to_row[candidate_id]]\n",
    "            for candidate_id in candidate_ids\n",
    "        ]\n",
    "\n",
    "        \n",
    "        # pad candidate_ids with 0s\n",
    "        candidate_ids += [0] * (15 - len(candidate_ids))\n",
    "        candidate_description_embeddings += torch.zeros(15 - len(candidate_description_embeddings), 384)\n",
    "\n",
    "        candidate_description_embeddings = torch.stack(candidate_description_embeddings)\n",
    "        \n",
    "\n",
    "        batch_context_embeddings.append(context_embeddings[index])\n",
    "        batch_entity_embeddings.append(entity_embeddings[index])\n",
    "        candidate_ids_batch.append(candidate_ids)\n",
    "        candidate_description_embeddings_batch.append(candidate_description_embeddings)\n",
    "\n",
    "    # batch_context_embeddings is a list of tensors thus we have to use stack\n",
    "    batch_context_embeddings = torch.stack(batch_context_embeddings)\n",
    "    batch_entity_embeddings = torch.stack(batch_entity_embeddings)\n",
    "    # candidate_ids_batch is a list of lists, convert it to a tensor\n",
    "    candidate_ids_batch = torch.tensor(candidate_ids_batch, dtype=torch.long, device=device)\n",
    "    candidate_description_embeddings_batch = torch.stack(candidate_description_embeddings_batch)\n",
    "\n",
    "    # move everything to device\n",
    "    batch_context_embeddings = batch_context_embeddings.to(device)\n",
    "    batch_entity_embeddings = batch_entity_embeddings.to(device)\n",
    "    candidate_ids_batch = candidate_ids_batch.to(device)\n",
    "    candidate_description_embeddings_batch = candidate_description_embeddings_batch.to(device)\n",
    "\n",
    "    return batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=lambda x: pytorch_utils.EntityDataset.collate_fn_train(x, device=device, entity_embeddings=dataset.entity_embeddings,context_embeddings=dataset.context_embeddings,syntax_candidates_list=dataset.syntax_candidates))\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=lambda x: pytorch_utils.EntityDataset.collate_fn_test(x, device=device, entity_embeddings=test_dataset.entity_embeddings,context_embeddings=test_dataset.context_embeddings,syntax_candidates_list=test_dataset.syntax_candidates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntityClassifier(torch.nn.Module):\n",
    "    def __init__(self, device='cuda'):\n",
    "        # This sequential layer will calculate a probability for each candidate entity, \n",
    "        # Since we will have CrossEntropyLoss as our loss function, we don't need to apply softmax\n",
    "        # The input to this layer will be the concatenation of the sentence embedding, entity embedding, and candidate description embedding\n",
    "        # The output will be single number, since it will be the probability of the candidate entity being the correct entity\n",
    "        # We pass each candidate once and get the probability of it being the correct entity\n",
    "        # Select the one with the highest probability\n",
    "        super().__init__()\n",
    "        self.sequential = torch.nn.Sequential(\n",
    "            torch.nn.Linear(384*2 * 4, 384*2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.3),\n",
    "            torch.nn.Linear(384*2, 1)\n",
    "        )\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch = x\n",
    "        # The shapes are:\n",
    "        # batch_context_embeddings: (batch_size, 384)\n",
    "        # batch_entity_embeddings: (batch_size, 384)\n",
    "        # candidate_ids_batch: (batch_size, 8)\n",
    "        # candidate_description_embeddings_batch: (batch_size, 8, 384)\n",
    "\n",
    "        context_entity_embed = torch.cat((batch_context_embeddings, batch_entity_embeddings), dim=1).to(self.device)\n",
    "        mean_embed = (batch_context_embeddings + batch_entity_embeddings) / 2\n",
    "\n",
    "\n",
    "        candidate_preds = torch.zeros((candidate_ids_batch.shape[0], candidate_ids_batch.shape[1]), device=self.device)\n",
    "        for i in range(candidate_ids_batch.shape[1]):\n",
    "            # Get the current candidate of all the batches\n",
    "            candidate_description_embed = candidate_description_embeddings_batch[:,i,:]\n",
    "            # The shape of candidate_description_embed is (batch_size, 384)\n",
    "            # Concatenate the sentence_document_entity_embed and candidate_description_embed\n",
    "            candidate_embed = torch.cat((context_entity_embed, candidate_description_embed), dim=1)\n",
    "            difference_embed = torch.abs(mean_embed - candidate_description_embed)\n",
    "            candidate_embed = torch.cat((candidate_embed, difference_embed), dim=1)\n",
    "            # The shape of candidate_embed is (batch_size, 384 * 3)\n",
    "            # Pass it through the sequential layer\n",
    "            candidate_pred = self.sequential(candidate_embed)\n",
    "            # The shape of candidate_pred is (batch_size, 1)\n",
    "            # we squeeze to get into shape (batch_size,)\n",
    "            candidate_preds[:,i] = candidate_pred.squeeze()\n",
    "        return candidate_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EntityClassifier(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_items = pd.read_csv(DATA_DIR + 'wiki_lite/wiki_items.csv')\n",
    "# index wiki_items by id\n",
    "wiki_items = wiki_items.set_index('item_id')\n",
    "# Create item_id to wikipedia_title map\n",
    "item_id_to_title = wiki_items['wikipedia_title'].to_dict()\n",
    "\n",
    "enwiki_redirects = pd.read_csv(DATA_DIR + 'wiki_lite/enwiki_redirects.tsv', sep='\\t', header=None, names=['source', 'target'])\n",
    "# index enwiki_redirects by source\n",
    "enwiki_redirects = enwiki_redirects.set_index('source')\n",
    "# create source to target map\n",
    "source_to_target = enwiki_redirects['target'].to_dict()\n",
    "\n",
    "\n",
    "def get_predictions():\n",
    "    # let's do predictions on the test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        predictions = []\n",
    "        prediction_indexes = []\n",
    "        for i, data in enumerate(test_dataloader):\n",
    "            batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch = data\n",
    "            outputs = model((batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch))\n",
    "            # which index has the highest value?\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            prediction_indexes.extend(predicted.tolist())\n",
    "            # predicted is shape (batch_size)\n",
    "            # we want to grab the best candidate for batch item i\n",
    "            # i.e the candidate_ids is of shape (batch_size, 5)\n",
    "            # we want to grab the best candidate for batch item i\n",
    "            # i.e get it to shape (batch_size)\n",
    "            best_candidates = candidate_ids_batch[torch.arange(candidate_ids_batch.size(0)), predicted]\n",
    "\n",
    "            # Append the best candidates to the predictions list\n",
    "            predictions.extend(best_candidates.tolist())\n",
    "\n",
    "    wiki_urls = []\n",
    "    not_found = 0\n",
    "    found = 0\n",
    "    # Now we will map these into wikipedia_urls\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] == 0:\n",
    "            # if the prediction is 0, we will append a blank url\n",
    "            wiki_urls.append('NOT_FOUND')\n",
    "            not_found += 1\n",
    "            continue\n",
    "        wikipedia_title = item_id_to_title[predictions[i]]\n",
    "        # does this wikipedia title exist in the redirects?\n",
    "        if wikipedia_title in source_to_target:\n",
    "            # if it does, we will replace it with the redirect\n",
    "            new_title = source_to_target[wikipedia_title]\n",
    "            wikipedia_title = new_title\n",
    "        # Now replace the spaces with underscores\n",
    "        wikipedia_title = wikipedia_title.replace(' ', '_')\n",
    "        # And add the wikipedia url\n",
    "        wiki_urls.append(f'http://en.wikipedia.org/wiki/{wikipedia_title}')\n",
    "        found += 1\n",
    "\n",
    "    # print(f'Found {found} wikipedia urls')\n",
    "    # print(f'Not found {not_found} wikipedia urls')\n",
    "    # print(f'Percentage of wikipedia urls found: {found / (found + not_found)}')\n",
    "    \n",
    "    return wiki_urls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 0.0 Avg shape: 0.0 | Valid F1: 0.0:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19 loss: 0.19278715625861603 Avg shape: 14.799650043744531 | Valid F1: 0.7848570805149466: 100%|██████████| 20/20 [06:09<00:00, 18.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest F1: 0.7902029238490073 at epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "validation = pd.read_csv(DATA_DIR + 'validation_prepped_with_item_id.csv')\n",
    "ground_truth = validation['2'].to_list()\n",
    "\n",
    "\n",
    "# loss and optimizer\n",
    "from torch import optim\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "# training loop\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "pbar = tqdm(range(epochs))\n",
    "highest_f1 = 0.0\n",
    "best_epoch = 0\n",
    "pbar.set_description(f'Epoch 0 loss: 0.0 Avg shape: 0.0 | Valid F1: 0.0')\n",
    "for epoch in pbar:\n",
    "    running_loss = 0.0\n",
    "    valid_f1 = 0.0\n",
    "    shapes = []\n",
    "    model.train()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch, labels_batch = data\n",
    "        shapes.append(batch_context_embeddings.shape[0])\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model((batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch))\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    wiki_urls = get_predictions()\n",
    "    # f1 from scikit-learn\n",
    "    from sklearn.metrics import f1_score\n",
    "    valid_f1 = f1_score(ground_truth, wiki_urls, average='micro')\n",
    "    pbar.set_description(f'Epoch {epoch} loss: {running_loss / len(dataloader)} Avg shape: {sum(shapes) / len(shapes)} | Valid F1: {valid_f1}')\n",
    "    pbar.update()\n",
    "\n",
    "    if valid_f1 > highest_f1: # type: ignore\n",
    "        highest_f1 = valid_f1\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'best_model3.pt')\n",
    "\n",
    "print(f'Highest F1: {highest_f1} at epoch {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4 loss: 0.17278752017934088 Avg shape: 14.799650043744531 | Valid F1: 0.7879118481344097:  10%|█         | 5/50 [01:43<15:34, 20.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 26\u001b[0m\n\u001b[0;32m     24\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# forward + backward + optimize\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_context_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_entity_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_ids_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_description_embeddings_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels_batch)\n\u001b[0;32m     28\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 42\u001b[0m, in \u001b[0;36mEntityClassifier.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     39\u001b[0m candidate_embed \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((candidate_embed, difference_embed), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;66;03m# The shape of candidate_embed is (batch_size, 384 * 3)\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Pass it through the sequential layer\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m candidate_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcandidate_embed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# The shape of candidate_pred is (batch_size, 1)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# we squeeze to get into shape (batch_size,)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m candidate_preds[:,i] \u001b[38;5;241m=\u001b[39m candidate_pred\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\aybar\\Documents\\CS423-Project-3\\.venv\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# loss and optimizer\n",
    "from torch import optim\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "# training loop\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "epochs = 50\n",
    "pbar = tqdm(range(epochs))\n",
    "highest_f1 = 0.0\n",
    "best_epoch = 0\n",
    "for epoch in pbar:\n",
    "    running_loss = 0.0\n",
    "    valid_f1 = 0.0\n",
    "    shapes = []\n",
    "    model.train()\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch, labels_batch = data\n",
    "        shapes.append(batch_context_embeddings.shape[0])\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = model((batch_context_embeddings, batch_entity_embeddings, candidate_ids_batch, candidate_description_embeddings_batch))\n",
    "        loss = criterion(outputs, labels_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    wiki_urls = get_predictions()\n",
    "    # f1 from scikit-learn\n",
    "    from sklearn.metrics import f1_score\n",
    "    valid_f1 = f1_score(ground_truth, wiki_urls, average='micro')\n",
    "    pbar.set_description(f'Epoch {epoch} loss: {running_loss / len(dataloader)} Avg shape: {sum(shapes) / len(shapes)} | Valid F1: {valid_f1}')\n",
    "    pbar.update()\n",
    "\n",
    "    if valid_f1 > highest_f1: # type: ignore\n",
    "        highest_f1 = valid_f1\n",
    "        best_epoch = epoch\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "\n",
    "print(f'Highest F1: {highest_f1} at epoch {best_epoch}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the best model\n",
    "model.load_state_dict(torch.load('best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_urls = get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(DATA_DIR + 'test.csv')\n",
    "# train = pd.read_csv(DATA_DIR + 'train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>entity_tag</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wiki_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65002</th>\n",
       "      <td>65002</td>\n",
       "      <td>Dejan</td>\n",
       "      <td>B</td>\n",
       "      <td>Dejan Koturovic</td>\n",
       "      <td>?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  token entity_tag     full_mention wiki_url\n",
       "65002  65002  Dejan          B  Dejan Koturovic        ?"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_nan = test['wiki_url'].notna()\n",
    "not_nme = test['wiki_url'] != '--NME--'\n",
    "# train_not_nan = train['wiki_url'].notna()\n",
    "# train_not_nme = train['wiki_url'] != '--NME--'\n",
    "test.loc[(not_nan & not_nme) & (test.id == 65002)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.loc[not_nan & not_nme, 'wiki_url'] = wiki_urls\n",
    "# train.loc[train_not_nan & train_not_nme, 'wiki_url'] = train_wiki_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace NaN or --NME-- with NOT_FOUND\n",
    "test['wiki_url'] = test['wiki_url'].fillna('NOT_FOUND')\n",
    "test['wiki_url'] = test['wiki_url'].replace('--NME--', 'NOT_FOUND')\n",
    "# train['wiki_url'] = train['wiki_url'].fillna('NOT_FOUND')\n",
    "# train['wiki_url'] = train['wiki_url'].replace('--NME--', 'NOT_FOUND')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>token</th>\n",
       "      <th>entity_tag</th>\n",
       "      <th>full_mention</th>\n",
       "      <th>wiki_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65002</th>\n",
       "      <td>65002</td>\n",
       "      <td>Dejan</td>\n",
       "      <td>B</td>\n",
       "      <td>Dejan Koturovic</td>\n",
       "      <td>http://en.wikipedia.org/wiki/Dejan_Koturović</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  token entity_tag     full_mention  \\\n",
       "65002  65002  Dejan          B  Dejan Koturovic   \n",
       "\n",
       "                                           wiki_url  \n",
       "65002  http://en.wikipedia.org/wiki/Dejan_Koturović  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[test.id == 65002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"-DOCSTART- (947testa CRICKET) CRICKET - LEICESTERSHIRE TAKE OVER AT TOP AFTER INNINGS VICTORY .  LONDON 1996-08-30  West Indian all-rounder Phil Simmons took four for 38 on Friday as Leicestershire beat Somerset by an innings and 39 runs in two days to take over at the head of the county championship .  Their stay on top , though , may be short-lived as title rivals Essex , Derbyshire and Surrey all closed in on victory while Kent made up for lost time in their rain-affected match against Nottinghamshire .  After bowling Somerset out for 83 on the opening morning at Grace Road , Leicestershire extended their first innings by 94 runs before being bowled out for 296 with England discard Andy Caddick taking three for 83 .  Trailing by 213 , Somerset got a solid start to their second innings before Simmons stepped in to bundle them out for 174 .  Essex , however , look certain to regain their top spot after Nasser Hussain and Peter Such gave them a firm grip on their match against Yorkshire at Headingley .  Hussain , considered surplus to England 's one-day requirements , struck 158 , his first championship century of the season , as Essex reached 372 and took a first innings lead of 82 .  By the close Yorkshire had turned that into a 37-run advantage but off-spinner Such had scuttled their hopes , taking four for 24 in 48 balls and leaving them hanging\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(test.token.fillna('', inplace=False).to_list()[:250])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # One problem, Simmons does not retrieve the cricket player, but querying for Phil Simmons does.\n",
    "# # TODO: Fix this, one idea is to group by per doc id, check if this token has a better previous full mention\n",
    "# display(wiki_items[wiki_items.index.isin(test_dataset.anchor_to_candidate['simmons'])])\n",
    "\n",
    "# print('____')\n",
    "\n",
    "# display(wiki_items[wiki_items.index.isin(test_dataset.anchor_to_candidate['phil simmons'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now create a .csv file from id, wiki_url\n",
    "test[['id', 'wiki_url']].to_csv('submission_bge.csv', index=False)\n",
    "# train[['id', 'wiki_url']].to_csv('train_with_doc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
